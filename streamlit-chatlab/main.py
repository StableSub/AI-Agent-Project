import streamlit as st
import asyncio
from llm_model import load_model
from mcp import ClientSession, StdioServerParameters
from mcp.client.stdio import stdio_client
from langchain_mcp_adapters.tools import load_mcp_tools
from langchain_mcp_adapters.prompts import load_mcp_prompt
from langgraph.prebuilt import create_react_agent


st.set_page_config(page_title='ChatGPT', page_icon='ğŸ˜€')
st.title('My_Little_LLM')
st.caption("ë­ì²´ì¸ ë° ìŠ¤íŠ¸ë¦¼ë¦¿ í…ŒìŠ¤íŠ¸")

server_params = StdioServerParameters(
    command="python",
    args=["MCP/server.py"],
)

with st.sidebar:
    "[ê¹ƒí—ˆë¸Œ](https://github.com/StableSub)"

llm = load_model.load_llm()
    
async def run():
    async with stdio_client(server_params) as (read, write):
        async with ClientSession(read, write) as session:
            await session.initialize()

            tools = await load_mcp_tools(session)
            agent = create_react_agent(llm, tools)
            
            # ì±„íŒ… ê¸°ë¡ ì´ˆê¸°í™”
            if "messages" not in st.session_state:
                st.session_state.messages = [{"role": "assistant", "content": "ë­ê°€ ê¶ê¸ˆí•´?"}] # session_stateëŠ” ì„œë²„ RAMì— ë°ì´í„°ë¥¼ ì €ì •í•˜ì—¬ ë”•ì…”ë„ˆë¦¬ í˜•íƒœë¡œ ë°ì´í„° ì €ì¥

            # ë Œë”ë§ ì‹œ ê¸°ì¡´ ì±„íŒ… ê¸°ë¡ì„ ë³´ì—¬ì¤Œ
            for message in st.session_state.messages:
                with st.chat_message(message["role"]): # withì€ ì»¨í…ìŠ¤íŠ¸ ê´€ë¦¬ì ë¬¸ë²•ìœ¼ë¡œ ë¦¬ì†ŒìŠ¤ë¥¼ ì—´ê³  ìë™ìœ¼ë¡œ ë‹«ê²Œ í•¨
                    st.markdown(message["content"])

            # ì±„íŒ…ì„ ì…ë ¥í•  ìˆ˜ ìˆëŠ” ê³³ì„ ë§Œë“¤ê³ , ìœ ì €ì˜ ì±„íŒ…ì„ ë©”ëª¨ë¦¬ì— ì €ì¥
            if user_input := st.chat_input("Say something"):
                with st.chat_message("user"):
                    st.markdown(user_input)
                st.session_state.messages.append({"role": "user", "content" : user_input})
                with st.chat_message("assistant"):
                    prompts = await load_mcp_prompt(
                        session, "default_prompt", arguments={"message": user_input}
                    )
                    response = await agent.ainvoke({"messages": prompts})
                    st.markdown(response["messages"][-1].content)
                st.session_state.messages.append({"role": "assistant", "content": response})
                
asyncio.run(run())