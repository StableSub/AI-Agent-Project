import os, sys, asyncio, hashlib, tempfile, time
import streamlit as st

from llm_model import load_model
from mcp import ClientSession, StdioServerParameters
from mcp.client.stdio import stdio_client
from langchain_mcp_adapters.tools import load_mcp_tools
from langchain_mcp_adapters.prompts import load_mcp_prompt
from langgraph.prebuilt import create_react_agent
from langchain.tools.retriever import create_retriever_tool
import pandas as pd

from rag_processsing import *
from data_processing import *

target_dir1 = "/Users/anjeongseob/Desktop/Storage/Python/AI-Agent/streamlit-chatlab/data/meta"
target_dir2 = "/Users/anjeongseob/Desktop/Storage/Python/AI-Agent/streamlit-chatlab/data/uploads"

for target_dir in [target_dir1, target_dir2]:
    for file in os.listdir(target_dir):
        file_path = os.path.join(target_dir, file)
        if os.path.isfile(file_path):
            os.remove(file_path)
        elif os.path.isdir(file_path):
            import shutil
            shutil.rmtree(file_path)

os.environ["TOKENIZERS_PARALLELISM"] = "false"

st.set_page_config(page_title="Sub's Agent", page_icon="ğŸ˜€")
st.title("My Little AI Agent")
st.caption("AI Agent Prototype")

LLM = load_model.load_llm()

SERVER_PARAMS = StdioServerParameters(
    command=sys.executable,
    args=["-u", os.path.abspath("MCP/server.py")],
)

# Streamlitì˜ ì„¸ì…˜ ìƒíƒœ ì´ˆê¸°í™”.
# ì‚¬ìš©ìì™€ LLM ê°„ì˜ ëŒ€í™” ë‚´ìš©, ì—…ë¡œë“œ íŒŒì¼ ì˜ˆì‹œ ë° retriever ê°ì²´ ë“±ì„ ì´ˆê¸°ê°’ìœ¼ë¡œ ì„¤ì •.
def init_state():
    if "messages" not in st.session_state:
        st.session_state.messages = [{"role": "assistant", "content": "ì§ˆë¬¸í•´ ë³´ì„¸ìš”!"}]
    if "retriever" not in st.session_state:
        st.session_state.retriever = None
    if "agent_tool_count" not in st.session_state:
        st.session_state.agent_tool_count = 0
    if "uploaded_file" not in st.session_state:
        st.session_state.uploaded_file = None

init_state()

with st.sidebar:
    st.markdown("### ì˜µì…˜")
    sample_rows = st.number_input("ìƒ˜í”Œ ë¡œë”© í–‰ ìˆ˜", min_value=10, max_value=2000, value = 100, step=10)

uploaded_file = st.file_uploader("íŒŒì¼ì„ ì—…ë¡œë“œí•˜ì„¸ìš”", type=list({"csv", "tsv", "txt"}))

if uploaded_file:
    file_bytes = uploaded_file.getvalue()
    file_hash = hashlib.md5(file_bytes).hexdigest()

    if st.session_state.get("file_hash") != file_hash:
        dsid, raw_path, ext = save_upload_to_disk(uploaded_file)
                
        st.session_state["file_hash"] = file_hash
        st.session_state["dsid"] = dsid
        st.session_state["raw_path"] = str(raw_path)
        st.session_state["ext"] = ext
        
        st.success(f"ì €ì¥ ì™„ë£Œ - dataset_id: {dsid} ê²½ë¡œ: {raw_path}")
        
        try:
            sniff_info = sniff_file(
                raw_path=raw_path,
                ext=ext
            )
        except Exception as e:
            st.error(f"ìŠ¤ë‹ˆí•‘ ì˜¤ë¥˜: {e}")
            st.stop()
            
        with st.spinner("ìƒ˜í”Œ ë¡œë”© ì¤‘..."):
            try:
                df, sample_info = sample_load(raw_path=raw_path, sniff_info=sniff_info, sample_rows=int(sample_rows))
            except Exception as e:
                write_meta(dsid, {"sniff": sniff_info, "error": str(e)})
                st.error(f"ë¡œë“œ ì˜¤ë¥˜: {e}")
                st.stop()
        meta = {
            "sniff": sniff_info,
            "shape_sample": list(df.shape),
            "shape_total": sample_info.get("shape_total"),
            "columns": list(df.columns),
            "ext": ext,
            "raw_path": str(raw_path),
        }
        write_meta(dsid, meta)
        
        st.session_state["meta"] = meta
        st.session_state["preview_df"] = df.head(20)
        st.session_state["dtype_df"] = pd.DataFrame({
            "column": df.columns,
            "null_count": df.isnull().sum().values,
            "null_ratio": (df.isnull().mean() * 100).round(2).values,
            "dtype": df.dtypes.astype(str).values,
        })
            
    meta = st.session_state["meta"]
    df_preview = st.session_state["preview_df"]
    dtype_df = st.session_state["dtype_df"]
    
    c1, c2, c3, c4 = st.columns(4)
    n_rows, n_cols = meta["shape_total"]
    c2.metric("í–‰ ìˆ˜(ì¶”ì •)", f"{n_rows:,}")
    c3.metric("ì—´ ìˆ˜", f"{n_cols:,}")
    c4.metric("íŒŒì¼ ìœ í˜•", meta["sniff"]["filetype"])
    
    with st.expander("ìŠ¤ë‹ˆí•‘ ê²°ê³¼ ë³´ê¸°", expanded=False):
        st.json(meta["sniff"])
    
    st.subheader("ë¯¸ë¦¬ë³´ê¸° (head 20)")
    st.dataframe(df_preview, use_container_width=True)
        
    st.subheader("ì»¬ëŸ½/íƒ€ì… ìš”ì•½")
    st.dataframe(dtype_df, use_container_width=True)
    
    with st.expander("ê¸°ë³¸ í†µê³„ (describe, numeric)", expanded=False):
        num_df = dtype_df.select_dtypes(include="number")
        if not num_df.empty:
            st.dataframe(num_df.describe().T, use_container_width=True)
        else:
            st.info("ìˆ˜ì¹˜í˜• ì»¬ëŸ¼ì´ ì—†ìŠµë‹ˆë‹¤.")
            
    dsid = st.session_state["dsid"]
    st.caption(f"ë©”íƒ€ ì €ì¥ ìœ„ì¹˜: '{META_DIR / f'{dsid}.json'}'")
    
    if "retriever" not in st.session_state or st.session_state.retriever is None:
        retriever_info = st.info("Retriever ìƒì„± ì¤‘...")
        st.session_state.retriever = build_retriever_from_csv(uploaded_file)
        retriever_info.empty()
        
else:
    st.info("ì¢Œì¸¡ ë˜ëŠ” ìœ„ì˜ ì—…ë¡œë”ë¡œ CSV/Excel/Parquet íŒŒì¼ì„ ì˜¬ë¦¬ì„¸ìš”. ì—…ë¡œë“œí•˜ë©´ ìë™ìœ¼ë¡œ ë¯¸ë¦¬ë³´ê¸°ë¥¼ ìƒì„±í•©ë‹ˆë‹¤.")

# ì—¬íƒœê¹Œì§€ ì €ì¥ëœ ë©”ì„¸ì§€ ì¶œë ¥.
for m in st.session_state.messages:
    with st.chat_message(m["role"]):
        st.markdown(m["content"])

# ì‚¬ìš©ì ì§ˆë¬¸ì„ ë°›ì•„ MCP Agentë¥¼ ì‹¤í–‰í•˜ê³ , ì ì ˆí•œ íˆ´ì„ ì‚¬ìš©í•´ ì‘ë‹µ ìƒì„±.
async def run(user_input: str):
    """ë§¤ ì…ë ¥ë§ˆë‹¤ 1íšŒ í˜¸ì¶œ: MCP ì—°ê²° â†’ íˆ´ êµ¬ì„± â†’ ì—ì´ì „íŠ¸ ìƒì„±/í˜¸ì¶œ."""
    async with stdio_client(SERVER_PARAMS) as (read, write): # MCP ì„œë²„ì— ì—°ê²°.
        async with ClientSession(read, write) as session: # íˆ´ ë° ë¥´í¼í”„íŠ¸ ë¡œë”©ì„ ìœ„í•´ ì´ˆê¸°í™” ì‹¤í–‰.
            await session.initialize()
            
            # MCPì— ë“±ë¡ëœ íˆ´ë“¤ì„ LangChain Agentê°€ ì‚¬ìš©í•  ìˆ˜ ìˆë˜ë¡ ë¦¬ìŠ¤íŠ¸ë¡œ ë¡œë“œ
            mcp_tools = await load_mcp_tools(session)
            tools = list(mcp_tools)

            # ì—…ë¡œë“œëœ ë¬¸ì„œê°€ ìˆìœ¼ë©´, í•´ë‹¹ ë¬¸ì„œì—ì„œ ê²€ìƒ‰í•  ìˆ˜ ìˆëŠ” retrieverë¥¼ LangChain íˆ´ë¡œ ë“±ë¡.
            if st.session_state.retriever:
                retriever_tool = create_retriever_tool(
                    st.session_state.retriever,
                    # toll ì´ë¦„ ë° Agentê°€ ì–´ë–¤ ì§ˆë¬¸ì— ì´ íˆ´ì„ ì‚¬ìš©í• ì§€ë¥¼ ê²°ì •.
                    name="doc_search",
                    description=(
                        "ì—…ë¡œë“œëœ ë¬¸ì„œì—ì„œ ì§ˆë¬¸ê³¼ ê´€ë ¨ëœ ë‚´ìš©ì„ ì°¾ìŠµë‹ˆë‹¤. "
                        "ìš”ì•½/ê°œìš”/í•µì‹¬ ì •ë¦¬ ë“±ë„ ì´ ë„êµ¬ë¡œ í•„ìš”í•œ ê·¼ê±°ë¥¼ ìˆ˜ì§‘í•œ í›„ ì‘ì„±í•˜ì„¸ìš”."
                    ),
                )
                tools.append(retriever_tool)
                if not st.session_state.retriever:
                    st.warning("retriever ìƒì„± ì‹¤íŒ¨")

            # LLMì´ ììœ ë¡­ê²Œ íˆ´ì„ ì„ íƒ.
            agent = create_react_agent(LLM, tools)

            # default_promptë¥¼ ê¸°ë°˜ìœ¼ë¡œ LLMì´ ì‚¬ìš©í•  ì´ˆê¸° ë©”ì„¸ì§€ ìƒì„±.
            prompts = await load_mcp_prompt(session, "default_prompt", arguments={"message": user_input})
            
            # LLM Agentë¥¼ ì‹¤í–‰í•˜ì—¬ ì‘ë‹µ ìƒì„±.
            response = await agent.ainvoke({"messages": prompts})
            answer = response["messages"][-1].content
            return answer
        
if user_input := st.chat_input("Say something"):
    with st.chat_message("user"):
        st.markdown(user_input)
    st.session_state.messages.append({"role": "user", "content" : user_input})
    with st.chat_message("assistant"):
        try:
            answer = asyncio.run(run(user_input))
        except Exception as e:
            answer = f"ì—ëŸ¬ê°€ ë°œìƒí–ˆìŠµë‹ˆë‹¤: {e}"
        st.markdown(answer)
    st.session_state.messages.append({"role": "assistant", "content": answer})